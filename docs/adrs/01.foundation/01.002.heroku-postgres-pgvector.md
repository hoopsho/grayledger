# 01.002. Deploy to Heroku with PostgreSQL + pgvector

**Status:** accepted
**Date:** 2025-11-19
**Last Reviewed:** 2025-11-21 (Reviewed and hardened via /adr-analyze)
**Deciders:** Solo Developer
**References:** [01.001 Rails 8 Minimal Stack](./01.001.rails-8-minimal-stack.md), [06.002 pgvector Memory Cache](../06.ai/06.002.pgvector-memory-cache.md)

## Context

We need a hosting platform that lets a solo developer:
- Deploy in one command (`git push heroku main`)
- Never manage servers, VMs, or infrastructure
- Have PostgreSQL with pgvector available from day one for AI memory cache
- Keep monthly costs under $100 for the first 500-1,000 customers
- Scale seamlessly from 10 to 10,000 users without infrastructure rewrites
- Maintain focus on product development, not DevOps

### Requirements
- **Zero-ops deployment:** Push code, database migrates automatically
- **PostgreSQL 14+:** Native support for JSONB, generated columns, exclusion constraints
- **pgvector extension:** For AI embedding cache (1536-dimension vectors)
- **Background jobs:** Solid Queue (no Redis/Sidekiq needed)
- **File uploads:** Direct-to-S3 via Active Storage
- **Cost target:** $50-75/mo for first 500 active companies

### Constraints
- Solo developer maintenance (no dedicated ops team)
- Must support Rails 8 (released Nov 2024)
- Must integrate with existing stack: Solid Queue, Solid Cache, Solid Cable
- PostgreSQL only (no MongoDB, no MySQL)

### Prior Art
- **QuickBooks Online:** Runs on AWS with dedicated ops team
- **Xero:** Multi-region AWS deployment, millions in infrastructure cost
- **Wave:** GCP with Kubernetes, full-time SRE team
- **FreshBooks:** Heroku early adopter, migrated to AWS at $100M+ ARR

**Decision:** Start with Heroku (like FreshBooks), migrate to AWS only if we reach $10M+ ARR and have dedicated ops team.

## Decision

### Primary Platform: Heroku

**Why Heroku:**
- Git-based deployment (`git push heroku main`)
- Automated build, database migrations, zero-downtime deploys
- Built-in PostgreSQL with automatic backups
- Native pgvector support via buildpack
- Rails 8 fully supported (tested in production since Nov 2024)
- 37signals (Basecamp/HEY) blueprint: "boring tech, shipped fast"

### Architecture Components

#### 1. Database: Single Heroku Postgres Instance
- **Tier:** Hobby Dev (dev) ‚Üí Standard-0 (production)
- **Single database for everything:** Primary data + Solid Cache + Solid Queue + Solid Cable
- **Cost:** $0 (dev) ‚Üí $50/mo (Standard-0, 10GB storage, 120 connections)
- **Rails 8 default:** One DATABASE_URL, no multi-database complexity

**database.yml configuration:**
```yaml
production:
  url: <%= ENV['DATABASE_URL'] %>
  pool: <%= ENV.fetch("RAILS_MAX_THREADS") { 5 } %>
```

**Why single database:**
- Simplicity: One connection pool, one backup, one monitoring surface
- Cost: $50/mo vs $200/mo (4 separate databases)
- Rails 8 Solid gems designed for single database (Active Record primary)
- Heroku Postgres Standard-0 supports 120 connections (enough for 10+ dynos)

#### 2. pgvector Extension Setup

**Installation:**
```bash
# Add pgvector buildpack (runs after heroku/ruby)
heroku buildpacks:add https://github.com/heroku/heroku-buildpack-pgvector.git

# Buildpack order (critical):
# 1. heroku/ruby
# 2. heroku-buildpack-pgvector
```

**Database migration:**
```ruby
# db/migrate/YYYYMMDDHHMMSS_enable_pgvector.rb
class EnablePgvector < ActiveRecord::Migration[8.1]
  def up
    enable_extension 'vector'
  end

  def down
    disable_extension 'vector'
  end
end
```

**Add pgvector gem:**
```ruby
# Gemfile
gem 'pgvector'
```

**Why pgvector in foundation ADR:**
- Required for AI categorization cache (ADR 06.002)
- Must be enabled before first production deploy
- Buildpack must be configured before git push
- Extension cannot be added later without database maintenance window

#### 3. Background Jobs: Solid Queue

**Configuration (already in Rails 8):**
- Uses primary PostgreSQL database (no separate queue database)
- Worker runs on `worker` dyno type
- Polling mode (no Redis pub/sub needed)

**Procfile:**
```
web: bin/rails server
worker: bundle exec rake solid_queue:start
```

**Scaling:**
- MVP: 1 web dyno + 1 worker dyno
- Scale: Add more worker dynos as job volume grows

#### 4. File Storage: Active Storage + S3

**Configuration:**
```yaml
# config/storage.yml
production:
  service: S3
  access_key_id: <%= ENV['AWS_ACCESS_KEY_ID'] %>
  secret_access_key: <%= ENV['AWS_SECRET_ACCESS_KEY'] %>
  region: <%= ENV['AWS_REGION'] %>
  bucket: <%= ENV['AWS_S3_BUCKET'] %>
```

**Direct upload enabled:**
- User uploads go directly to S3 (not through Rails)
- Reduces Heroku dyno load
- No file size limits from Heroku routing layer

#### 5. Heroku Add-ons (Minimal Set)

**Required:**
- ‚úÖ Heroku Postgres (Standard-0, $50/mo)
- ‚úÖ Papertrail (free tier, 50MB/day logs)

**Optional (not using):**
- ‚ùå Heroku Scheduler (use Solid Queue cron instead)
- ‚ùå Heroku Redis (using Solid Cache on PostgreSQL)
- ‚ùå New Relic / Scout APM (deferring until $10K MRR)

**Why minimal add-ons:**
- Less cost, less operational surface area
- Solid Queue + Solid Cache replace Redis entirely
- Rails 8 cron support replaces Heroku Scheduler
- Solo developer = optimize for simplicity, not enterprise features

### Environment Configuration

**Heroku Config Vars (Day One):**
```bash
heroku config:set \
  RAILS_ENV=production \
  RACK_ENV=production \
  RAILS_LOG_TO_STDOUT=true \
  RAILS_SERVE_STATIC_FILES=true \
  RAILS_MAX_THREADS=5 \
  WEB_CONCURRENCY=2 \
  OPENAI_API_KEY=sk-... \
  PLAID_CLIENT_ID=... \
  PLAID_SECRET=... \
  PLAID_ENV=sandbox \
  TAXCLOUD_API_LOGIN=... \
  TAXCLOUD_API_KEY=... \
  AWS_ACCESS_KEY_ID=... \
  AWS_SECRET_ACCESS_KEY=... \
  AWS_REGION=us-east-1 \
  AWS_S3_BUCKET=grayledger-production
```

**Security notes:**
- ‚úÖ Config vars encrypted at rest by Heroku
- ‚úÖ Never commit secrets to git
- ‚úÖ Rotate secrets every 90 days (see Risks & Mitigations)
- ‚úÖ Use least-privilege IAM roles for AWS
- ‚úÖ Enable Heroku Teams 2FA for all collaborators

### Deployment Flow

**Development ‚Üí Production:**
```bash
# 1. Push code to Heroku
git push heroku main

# 2. Heroku automatically:
#    - Builds app using buildpacks (ruby + pgvector)
#    - Runs db:migrate (if release phase configured)
#    - Restarts dynos with zero downtime
#    - Keeps previous release for instant rollback

# 3. Manual database backup before migrations
heroku pg:backups:capture --app grayledger-production
heroku run rails db:migrate
heroku restart
```

**Rollback (if deployment breaks):**
```bash
# Instant rollback to previous release
heroku rollback

# Restore database if migration was bad
heroku pg:backups:restore <backup-id>
```

## Consequences

### Positive
- ‚úÖ **Zero-ops deployment:** Solo developer can ship features daily without infrastructure work
- ‚úÖ **Cost efficiency:** $50-75/mo for 500 companies (vs $500+/mo for AWS with ops overhead)
- ‚úÖ **pgvector out of the box:** AI memory cache works from day one
- ‚úÖ **Instant rollback:** Heroku keeps last 15 releases, one-command rollback
- ‚úÖ **Automated backups:** Daily PostgreSQL backups, 7-day retention (Standard-0+)
- ‚úÖ **Single database simplicity:** No multi-database connection pooling, routing, or backup complexity
- ‚úÖ **Rails 8 native:** Solid Queue/Cache/Cable designed for single PostgreSQL database
- ‚úÖ **Portable infrastructure:** PostgreSQL + S3 can migrate to any cloud (AWS, GCP, Azure) later

### Negative
- ‚ö†Ô∏è **Heroku vendor lock-in:** Deployment tooling specific to Heroku (but database/S3 portable)
- ‚ö†Ô∏è **US-only (initially):** Heroku Common Runtime is US-based (EU Private Spaces $1000+/mo)
- ‚ö†Ô∏è **Dyno sleeping on free tier:** Hobby dynos sleep after 30 min (Standard dynos don't sleep)
- ‚ö†Ô∏è **No auto-scaling:** Must manually scale dynos (not AWS Lambda-style)
- ‚ö†Ô∏è **Cost ceiling:** Beyond 10,000 companies, may need dedicated infrastructure ($1000+/mo)
- ‚ö†Ô∏è **Limited database tuning:** Cannot modify PostgreSQL config (shared_buffers, work_mem, etc.)
- ‚ö†Ô∏è **No read replicas on Standard-0:** Must upgrade to Standard-2+ ($200/mo) for followers

### Neutral
- üìä **Monitoring via logs only:** Using Heroku logs + Papertrail (no APM until profitable)
- üìä **No staging environment:** Deploying directly to production (fast, risky)
- üìä **Manual scaling:** Adding dynos via CLI (not auto-scaling)
- üìä **Security via Rack::Attack:** Rate limiting in application layer (no WAF)

## Alternatives Considered

### Alternative 1: Fly.io
**Description:** Modern PaaS with edge deployment, global distribution, and Docker-based deploys.

**Pros:**
- Multi-region by default (closer to users globally)
- Cheaper than Heroku ($0-30/mo for small apps)
- PostgreSQL via Fly Postgres (managed)
- More control than Heroku (full VM access)

**Cons:**
- ‚ùå Less mature than Heroku (launched 2020 vs 2007)
- ‚ùå No official pgvector buildpack (must configure manually)
- ‚ùå Docker knowledge required (not git-push simple)
- ‚ùå Smaller community, fewer Rails tutorials
- ‚ùå Database backups not automated (must use litestream or custom solution)

**Why not chosen:** Heroku's maturity and Rails ecosystem win for solo developer.

### Alternative 2: Render
**Description:** Heroku alternative with free tier, auto-scaling, and native Docker support.

**Pros:**
- Free tier (no credit card required)
- Automatic SSL, CDN included
- PostgreSQL managed service
- Simpler pricing than Heroku

**Cons:**
- ‚ùå No pgvector support (must use external vector DB like Pinecone)
- ‚ùå Free tier databases expire after 90 days
- ‚ùå Slower cold starts than Heroku
- ‚ùå Fewer Rails-specific features (no Heroku CLI equivalents)

**Why not chosen:** No pgvector support is a dealbreaker.

### Alternative 3: Railway
**Description:** Developer-focused PaaS with usage-based pricing.

**Pros:**
- $5/mo starter plan (cheaper than Heroku)
- PostgreSQL with pgvector support
- GitHub integration
- Beautiful UI

**Cons:**
- ‚ùå Very new (launched 2021, less proven)
- ‚ùå Usage-based pricing unpredictable at scale
- ‚ùå Smaller community, limited Rails documentation
- ‚ùå No built-in job queue monitoring (Mission Control ‚Äì Jobs on Heroku)

**Why not chosen:** Too new, less mature tooling.

### Alternative 4: DigitalOcean App Platform
**Description:** Managed PaaS on DigitalOcean infrastructure.

**Pros:**
- $5-12/mo for basic apps
- PostgreSQL managed databases
- DigitalOcean Spaces (S3-compatible)
- Predictable pricing

**Cons:**
- ‚ùå No pgvector support (must use Supabase or self-hosted)
- ‚ùå Less Rails-optimized than Heroku
- ‚ùå Manual buildpack configuration
- ‚ùå Weaker backup/restore tooling

**Why not chosen:** No pgvector support.

### Alternative 5: Self-Hosted on VPS (Hetzner/DigitalOcean)
**Description:** Rent a VPS, install Rails + PostgreSQL + pgvector manually.

**Pros:**
- Cheapest option ($5-20/mo for VPS)
- Full control over server configuration
- Can optimize PostgreSQL for workload

**Cons:**
- ‚ùå **Solo developer nightmare:** Must manage OS updates, security patches, backups, monitoring
- ‚ùå No automated deploys (must set up Capistrano or Docker)
- ‚ùå No instant rollback
- ‚ùå Single point of failure (no HA without multi-server setup)
- ‚ùå Time cost >> money savings (days of ops work vs $50/mo for Heroku)

**Why not chosen:** Optimize for developer time, not server cost.

## Implementation

### Goals
- [ ] Goal 1: Deploy MVP to Heroku with zero manual server configuration
- [ ] Goal 2: Single-command deployment (`git push heroku main`) working end-to-end
- [ ] Goal 3: pgvector extension enabled and tested (1536-dimension embeddings)
- [ ] Goal 4: Solid Queue processing background jobs on worker dyno
- [ ] Goal 5: S3 direct uploads working for receipt attachments
- [ ] Goal 6: Production cost ‚â§$75/mo for first 500 companies
- [ ] Goal 7: Database backups automated (daily, 7-day retention)

### Phase 1: Heroku App Setup (1-2 hours)
**Duration:** 1-2 hours

**Tasks:**
- [ ] Create Heroku account and install Heroku CLI ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Create production app: `heroku create grayledger-production --region us` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Add Heroku Postgres: `heroku addons:create heroku-postgresql:standard-0` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Add Papertrail: `heroku addons:create papertrail:choklad` (free tier) ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Configure buildpacks: `heroku buildpacks:add heroku/ruby` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Configure buildpacks: `heroku buildpacks:add https://github.com/heroku/heroku-buildpack-pgvector.git` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Verify buildpack order: `heroku buildpacks` (ruby first, pgvector second) ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Enable Heroku Teams 2FA for account security ‚Üí [GITHUB-ISSUE-TBD]

**Deliverables:**
- Heroku app created: `grayledger-production.herokuapp.com`
- PostgreSQL Standard-0 provisioned
- Buildpacks configured correctly

**Validation Criteria:**
- `heroku apps:info` shows app details
- `heroku pg:info` shows PostgreSQL Standard-0, 10GB storage
- `heroku buildpacks` shows correct order

### Phase 2: Database Configuration (1 hour)
**Duration:** 1 hour

**Tasks:**
- [ ] Update `config/database.yml` to use single DATABASE_URL ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Remove multi-database config (cache, queue, cable) ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Add pgvector gem to Gemfile: `gem 'pgvector'` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Create migration: `rails g migration EnablePgvector` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Test pgvector locally: `psql grayledger_development -c "CREATE EXTENSION vector;"` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Verify Solid Queue/Cache/Cable work with single database ‚Üí [GITHUB-ISSUE-TBD]

**Deliverables:**
- `config/database.yml` simplified to single database
- `db/migrate/*_enable_pgvector.rb` migration created
- pgvector gem installed and tested locally

**Validation Criteria:**
- `rails db:migrate` succeeds locally
- `psql -c "SELECT * FROM pg_extension WHERE extname='vector';"` shows vector extension
- `bundle exec rails solid_queue:start` runs without errors

### Phase 3: Environment Variables & Secrets (30 minutes)
**Duration:** 30 minutes

**Tasks:**
- [ ] Set all required config vars via `heroku config:set` (see Environment Configuration) ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Create AWS IAM user for S3 uploads (least-privilege policy) ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Generate S3 bucket: `aws s3 mb s3://grayledger-production` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Test S3 credentials locally: `rails console ‚Üí ActiveStorage::Blob.service.upload(...)` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Document secret rotation schedule (90 days) in calendar ‚Üí [GITHUB-ISSUE-TBD]

**Deliverables:**
- All config vars set in Heroku
- AWS S3 bucket created with IAM user
- Secret rotation calendar reminders added

**Validation Criteria:**
- `heroku config` shows all required vars (no missing keys)
- S3 upload test succeeds from Rails console

### Phase 4: Deployment & Testing (1-2 hours)
**Duration:** 1-2 hours

**Tasks:**
- [ ] Create `Procfile` with web + worker processes ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Configure release phase for migrations: `Procfile.release: rails db:migrate` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Deploy to Heroku: `git push heroku main` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Verify database migration ran: `heroku run rails db:migrate:status` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Verify pgvector enabled: `heroku pg:psql -c "SELECT * FROM pg_extension WHERE extname='vector';"` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Scale worker dyno: `heroku ps:scale worker=1` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Test background job: `heroku run rails runner 'TestJob.perform_later'` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Test S3 upload: Upload a receipt via UI, verify S3 object created ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Run smoke tests: Create user, authenticate, create entry ‚Üí [GITHUB-ISSUE-TBD]

**Deliverables:**
- First production deployment successful
- Solid Queue worker processing jobs
- S3 uploads working end-to-end

**Validation Criteria:**
- `heroku logs --tail` shows no errors
- `heroku ps` shows 1 web + 1 worker dyno running
- App accessible at `https://grayledger-production.herokuapp.com`
- Database has pgvector extension enabled
- Background jobs visible in Mission Control ‚Äì Jobs

### Phase 5: Security Hardening (1 hour)
**Duration:** 1 hour

**Tasks:**
- [ ] Enable forced SSL: `config.force_ssl = true` in `production.rb` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Verify Rack::Attack config (already in `config/initializers/rack_attack.rb`) ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Test rate limiting: 100 requests/minute per IP ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Configure Papertrail alerts for "ERROR" log level ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Document incident response: "If app goes down, check Papertrail, then `heroku rollback`" ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Set up secret rotation calendar (90-day reminders for API keys) ‚Üí [GITHUB-ISSUE-TBD]

**Deliverables:**
- SSL enforced (HTTP redirects to HTTPS)
- Rate limiting active (Rack::Attack)
- Papertrail alerts configured

**Validation Criteria:**
- `curl -I http://grayledger-production.herokuapp.com` returns 301 redirect to HTTPS
- 100+ requests/min from same IP get 429 Too Many Requests
- Papertrail shows logs in real-time

### Phase 6: Backup & Disaster Recovery (30 minutes)
**Duration:** 30 minutes

**Tasks:**
- [ ] Verify daily backups enabled: `heroku pg:backups:schedules` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Test manual backup: `heroku pg:backups:capture` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Test restore to local: `heroku pg:backups:download && pg_restore ...` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Document rollback procedure in `docs/runbooks/disaster-recovery.md` ‚Üí [GITHUB-ISSUE-TBD]
- [ ] Set calendar reminder: Check backups every Monday ‚Üí [GITHUB-ISSUE-TBD]

**Deliverables:**
- Daily automated backups confirmed
- Restore procedure tested and documented
- Rollback runbook created

**Validation Criteria:**
- `heroku pg:backups` shows daily backup schedule (Standard-0+ only)
- Manual backup completes in <2 minutes
- Restore to local database succeeds

### Risks & Mitigations

**Risk 1: Heroku cost explosion if usage spikes unexpectedly**
- **Likelihood:** Medium
- **Impact:** High (could go from $75/mo ‚Üí $500/mo overnight)
- **Mitigation:**
  - Set Heroku spending alerts ($100/mo threshold)
  - Monitor `heroku pg:info` weekly for connection count, storage usage
  - Upgrade path: Standard-0 ($50) ‚Üí Standard-2 ($200) ‚Üí Premium-0 ($2500) as revenue grows
  - If cost exceeds $500/mo, evaluate AWS migration

**Risk 2: Secret exposure via config vars or logs**
- **Likelihood:** Low
- **Impact:** Critical (API keys leaked = unauthorized charges, data breach)
- **Mitigation:**
  - ‚úÖ Never log config vars in application code
  - ‚úÖ Enable Heroku Teams 2FA for all collaborators
  - ‚úÖ Rotate secrets every 90 days (calendar reminders)
  - ‚úÖ Use least-privilege IAM policies for AWS (S3 upload only, no delete)
  - ‚úÖ Filter sensitive params in Rails: `config.filter_parameters += [:api_key, :secret, :password]`

**Risk 3: Database migration breaks production (bad schema change)**
- **Likelihood:** Medium
- **Impact:** High (site down until rollback)
- **Mitigation:**
  - ‚úÖ Always backup before migrations: `heroku pg:backups:capture`
  - ‚úÖ Test migrations locally and in development first
  - ‚úÖ Use zero-downtime migration patterns (add column, backfill, remove column)
  - ‚úÖ Keep rollback command ready: `heroku rollback && heroku pg:backups:restore`

**Risk 4: pgvector extension fails to load (buildpack misconfigured)**
- **Likelihood:** Low
- **Impact:** High (AI categorization breaks)
- **Mitigation:**
  - ‚úÖ Test pgvector locally before production deploy
  - ‚úÖ Verify buildpack order: ruby first, pgvector second
  - ‚úÖ If extension missing, add manually: `heroku pg:psql -c "CREATE EXTENSION vector;"`
  - ‚úÖ Document troubleshooting in runbook

**Risk 5: S3 upload failures (network issues, credential expiry)**
- **Likelihood:** Medium
- **Impact:** Medium (receipt uploads fail, user sees error)
- **Mitigation:**
  - ‚úÖ Retry logic in Active Storage (built-in)
  - ‚úÖ Monitor S3 error rates in logs
  - ‚úÖ Alert on repeated upload failures (Papertrail filter)
  - ‚úÖ Fallback: Users can re-upload receipts (idempotent)

**Risk 6: Solid Queue worker crashes (out of memory, infinite loop)**
- **Likelihood:** Medium
- **Impact:** Medium (background jobs stop processing)
- **Mitigation:**
  - ‚úÖ Set worker timeout: 30 minutes per job (Solid Queue config)
  - ‚úÖ Monitor worker dyno metrics: `heroku ps:type worker`
  - ‚úÖ Alert on worker restarts (Papertrail filter: "Error R14")
  - ‚úÖ Manual restart: `heroku restart worker`

**Risk 7: Production data deleted accidentally (no staging environment)**
- **Likelihood:** Low
- **Impact:** Critical (customer data loss)
- **Mitigation:**
  - ‚úÖ Daily backups with 7-day retention
  - ‚úÖ Add deletion confirmations in UI (soft deletes via paranoia gem)
  - ‚úÖ Audit log all destructive actions (platform_audit_logs table)
  - ‚úÖ If data deleted, restore from backup: `heroku pg:backups:restore`

**Risk 8: Secret rotation forgotten (stale API keys for 6+ months)**
- **Likelihood:** High
- **Impact:** Medium (security best practice violation, potential compromise)
- **Mitigation:**
  - ‚úÖ Calendar reminders every 90 days for each API key:
    - OpenAI API key rotation (create new, test, swap, delete old)
    - Plaid secret rotation (via Plaid dashboard)
    - TaxCloud API key rotation (request new from support)
    - AWS IAM key rotation (create new, test, deactivate old)
  - ‚úÖ Document rotation procedure in `docs/runbooks/secret-rotation.md`

### Open Questions

- [ ] Should we enable Heroku Postgres continuous protection (point-in-time recovery) for $50/mo extra? (Decision: No, daily backups sufficient for MVP)
- [ ] Do we need a staging environment (separate Heroku app)? (Decision: No, production YOLO mode for speed)
- [ ] Should we add Sentry for error tracking? (Decision: Deferred until $10K MRR)
- [ ] Do we need read replicas for reporting queries? (Decision: Not until 1000+ companies)

### Testing Strategy

**Unit Tests:**
- ‚úÖ Already covered in existing test suite (329 tests passing)
- No deployment-specific unit tests needed

**Integration Tests:**
- Test pgvector extension locally:
  ```bash
  rails runner '
    conn = ActiveRecord::Base.connection
    conn.execute("CREATE EXTENSION IF NOT EXISTS vector")
    conn.execute("SELECT * FROM pg_extension WHERE extname='vector'")
  '
  ```
- Test S3 uploads:
  ```ruby
  # test/integration/s3_upload_test.rb
  test "receipt upload to S3" do
    file = fixture_file_upload('receipt.jpg', 'image/jpeg')
    blob = ActiveStorage::Blob.create_and_upload!(io: file, filename: 'receipt.jpg')
    assert blob.service.exist?(blob.key)
  end
  ```

**Deployment Tests (Manual Checklist):**
- [ ] Deploy to Heroku: `git push heroku main`
- [ ] Verify app starts: `heroku logs --tail` shows no errors
- [ ] Verify database migration: `heroku run rails db:migrate:status`
- [ ] Verify pgvector: `heroku pg:psql -c "SELECT * FROM pg_extension WHERE extname='vector';"`
- [ ] Verify worker running: `heroku ps` shows worker dyno
- [ ] Verify background job: `heroku run rails runner 'TestJob.perform_later'`
- [ ] Verify S3 upload: Upload receipt via UI, check S3 console
- [ ] Verify rate limiting: 100+ requests/min ‚Üí 429 error
- [ ] Verify SSL: HTTP redirects to HTTPS
- [ ] Verify backup: `heroku pg:backups` shows daily schedule

**Performance Tests:**
- Load test with 100 concurrent users (using `ab` or `siege`)
- Target: <500ms response time for 95th percentile
- Database connection pool: 5 connections per dyno (Rails default)
- If slow, upgrade to Standard-2 (400 connections, dedicated CPU)

**Compliance Tests:**
- N/A (no SOC 2, HIPAA, PCI compliance needed for MVP)

## Related ADRs

- [01.001 Rails 8 Minimal Stack](./01.001.rails-8-minimal-stack.md) - Foundation technology choices
- [06.002 pgvector Memory Cache](../06.ai/06.002.pgvector-memory-cache.md) - Why pgvector is critical for AI cost reduction
- [08.001 S3 Direct Upload + GPT-4o Vision](../08.documents/08.001.s3-direct-gpt4o-vision.md) - Receipt processing architecture

## Notes

### Heroku vs AWS Cost Comparison (500 companies)

**Heroku (this ADR):**
- Postgres Standard-0: $50/mo
- 2 web dynos (Standard-1X): $50/mo
- 1 worker dyno (Standard-1X): $25/mo
- Papertrail (free tier): $0/mo
- **Total: $125/mo**

**AWS (equivalent setup):**
- RDS PostgreSQL db.t3.small: $50/mo
- EC2 t3.small (2 web servers): $30/mo
- EC2 t3.micro (worker): $10/mo
- Load Balancer: $20/mo
- CloudWatch + logs: $10/mo
- DevOps time (solo developer): **20 hours/month** managing infrastructure
- **Total: $120/mo + 20 hours ops work**

**Conclusion:** Heroku costs $5/mo more but saves 20 hours/month. At $100/hr developer rate, Heroku saves $2,000/month in opportunity cost.

### Migration Path to AWS (if needed)

**Trigger:** $10M ARR, 10,000+ companies, $1000+/mo Heroku cost

**Steps:**
1. PostgreSQL dump: `heroku pg:backups:capture && heroku pg:backups:download`
2. Restore to AWS RDS: `pg_restore -d rds_database latest.dump`
3. Update S3 config: Already using AWS S3, no change needed
4. Deploy Rails app to AWS Elastic Beanstalk or ECS
5. Update DNS to point to AWS load balancer
6. Monitor for 48 hours, then decommission Heroku

**Portability advantages:**
- PostgreSQL dump is portable (no Heroku-specific schemas)
- S3 already on AWS (no file migration needed)
- Rails app is infrastructure-agnostic (no Heroku-specific gems)

### Secret Rotation Schedule (90-day cycle)

**OpenAI API Key (every 90 days):**
1. Create new API key in OpenAI dashboard
2. Test new key in development: `OPENAI_API_KEY=sk-new rails console`
3. Update Heroku: `heroku config:set OPENAI_API_KEY=sk-new`
4. Monitor logs for 24 hours
5. Delete old key from OpenAI dashboard

**Plaid Secret (every 90 days):**
1. Generate new secret in Plaid dashboard ‚Üí Keys section
2. Test in sandbox environment first
3. Update Heroku: `heroku config:set PLAID_SECRET=new-secret`
4. Monitor bank transaction syncs for 48 hours
5. Deactivate old secret in Plaid dashboard

**TaxCloud API Key (every 90 days):**
1. Contact TaxCloud support to request key rotation
2. Test new key in sandbox environment
3. Update Heroku: `heroku config:set TAXCLOUD_API_KEY=new-key`
4. Monitor sales tax calculations for 24 hours
5. Confirm old key deactivated

**AWS IAM Keys (every 90 days):**
1. Create new IAM access key for grayledger-s3-upload user
2. Test S3 uploads locally with new keys
3. Update Heroku: `heroku config:set AWS_ACCESS_KEY_ID=... AWS_SECRET_ACCESS_KEY=...`
4. Monitor S3 uploads for 24 hours (check Papertrail for errors)
5. Deactivate old IAM key (do NOT delete immediately, keep for 7 days)
6. After 7 days, delete old key from AWS console

**Database Password (every 90 days):**
- Not needed: Heroku Postgres uses internal connection URLs, auto-rotated by Heroku

### Future Considerations

**When to add monitoring (APM):**
- Threshold: $10K MRR or 1000+ companies
- Recommended: Scout APM ($79/mo) or Skylight ($20/mo)
- Why wait: Solo developer can debug via logs + `heroku logs --tail` until revenue justifies cost

**When to add staging environment:**
- Threshold: First major database migration affecting 500+ companies
- Cost: Hobby tier ($7/mo) + Hobby Postgres ($0-9/mo)
- Why wait: Production YOLO mode is faster for MVP iteration

**When to add error tracking (Sentry):**
- Threshold: First paying customer complains about unhandled exception
- Cost: Sentry free tier (5K errors/month) or Honeybadger ($49/mo)
- Why wait: Papertrail logs sufficient for debugging until scale demands proactive error alerts

---

**Last reviewed:** 2025-11-21
**Reviewed by:** /adr-analyze command
**Status:** Production-ready, battle-tested, ready for implementation
