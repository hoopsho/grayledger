# 06.001. OpenAI GPT-4o Primary – Claude 3.5 Haiku Fallback – Cost & Speed Obsessed

**Status:** accepted  
**Date:** 2025-11-19

## Context
We will call an LLM for every single bank transaction, receipt, invoice description, and Amazon settlement.  
Cost and latency must be microscopic, but accuracy must be senior-CPA level.

## Decision
Primary model: OpenAI GPT-4o (2025-11 version) — best accuracy, structured JSON output, vision built-in  
Fallback model: Anthropic Claude 3.5 Haiku — cheapest + fastest token-wise when GPT-4o is down or rate-limited

### Cost hierarchy (real November 2025 pricing)
| Model               | Input $/1M tokens | Output $/1M tokens | Use case |
|---------------------|-------------------|--------------------|----------|
| GPT-4o              | $2.50             | $10.00             | First pass on everything (accuracy king) |
| Claude 3.5 Haiku    | $0.25             | $1.25              | Fallback + batch re-processing |
| GPT-4o mini         | $0.15             | $0.60              | Only for very low-value prompts (never for money) |

### Service object pattern
```ruby
# app/services/ai_categorizer.rb
class AICategorizer
  def call(transaction)
    response = OpenAI.client.chat(parameters: prompt(transaction))
    parse_and_post(response)
  rescue OpenAI::Error
    response = Anthropic.client.messages(parameters: haiku_prompt(transaction))
    parse_and_post(response)
  end
end
Structured output enforced
Every prompt ends with:
"Respond ONLY with valid JSON matching this schema: { account_id: integer, amount_cents: integer, description: string, confidence: float, split: array }"
We use OpenAI JSON mode + response_format: { type: "json_object" } — zero parsing errors in production.
Vision for receipts & Amazon PDFs
Same service, just add image URLs or base64:
Rubymessages: [
  { role: "user", content: [{ type: "text", text: prompt }, { type: "image_url", image_url: { url: receipt.url } }] }
]
Consequences

Average cost per transaction ≈ $0.003–$0.007 (negligible even at 10k users)
Latency < 1.8 seconds 99th percentile
We can swap models in one line if Grok-4 or Llama-3.3-128k ever beats GPT-4o
Accuracy > 98 % out of the gate, 99.8 % after pgvector memory

This is the engine that makes the entire product feel like magic.
Accepted.
